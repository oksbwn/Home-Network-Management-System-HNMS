import asyncio
import json
import uuid
import logging
from datetime import datetime, timezone
from typing import List, Dict, Any, Optional
from scapy.all import ARP, Ether, srp
from app.core.db import get_connection

logger = logging.getLogger(__name__)

async def resolve_hostname(ip: str) -> Optional[str]:
    try:
        import socket
        def sync_resolve():
            try:
                return socket.gethostbyaddr(ip)[0]
            except:
                return None
        return await asyncio.to_thread(sync_resolve)
    except:
        return None

async def scan_ports(ip: str, ports: List[int] = [
    21, 22, 23, 25, 53, 80, 110, 139, 143, 443, 445, 548, 587, 631, 993, 995, 1883, 2049, 2375, 3000, 32400, 3306, 3389, 5000, 5353, 5432, 5555, 5683, 5900, 6379, 8006, 8080, 8081, 8123, 8443, 8883, 8888, 9000, 9090, 9091, 10000
]) -> List[Dict[str, Any]]:
    # Use native asyncio for better performance
    semaphore = asyncio.Semaphore(50) # Allow more concurrency

    async def check_port(p):
        async with semaphore:
            try:
                # 1 second timeout
                fut = asyncio.open_connection(ip, p)
                reader, writer = await asyncio.wait_for(fut, timeout=1.0)
                writer.close()
                await writer.wait_closed()
                
                # Resolve service name in thread to avoid blocking loop
                def get_service():
                    import socket
                    try: return socket.getservbyport(p)
                    except: return "unknown"
                
                service = await asyncio.to_thread(get_service)
                return {"port": p, "protocol": "tcp", "service": service}
            except (asyncio.TimeoutError, ConnectionRefusedError, OSError):
                return None
            except Exception:
                return None

    results = await asyncio.gather(*(check_port(p) for p in ports))
    return [r for r in results if r]

async def scan_device(device_id: str, ip: str) -> List[Dict[str, Any]]:
    """Deep scan for a specific device."""
    top_ports = list(range(1, 1025))
    found = await scan_ports(ip, top_ports)
    
    def update_db():
        conn = get_connection()
        try:
            conn.execute("UPDATE devices SET open_ports = ?, last_seen = ? WHERE id = ?", [json.dumps(found), datetime.now(timezone.utc), device_id])
            conn.execute("DELETE FROM device_ports WHERE device_id = ?", [device_id])
            for p in found:
                conn.execute(
                    "INSERT INTO device_ports (device_id, port, protocol, service, last_seen) VALUES (?, ?, ?, ?, ?)",
                    [device_id, p["port"], p["protocol"], p["service"], datetime.now(timezone.utc)]
                )
            conn.commit()
        finally:
            conn.close()
    
    await asyncio.to_thread(update_db)
    return found

async def run_scan_job(scan_id: str, target: str, scan_type: str = "arp", options: Optional[Dict[str, Any]] = None):
    try:
        job_start = datetime.now(timezone.utc)
        logger.info(f"Starting scan job {scan_id} for target {target}")
        
        # 1. Ensure scan status is running with a start time
        def start_scan():
            conn = get_connection()
            try:
                conn.execute("UPDATE scans SET status = 'running', started_at = ?, error_message = NULL WHERE id = ?", [job_start, scan_id])
                conn.commit()
            finally:
                conn.close()
        await asyncio.to_thread(start_scan)

        # 2. Perform Network Discovery
        def network_discovery():
            try:
                logger.info(f"Triggering Scapy ARP discovery for {target}...")
                ans, unans = srp(Ether(dst="ff:ff:ff:ff:ff:ff")/ARP(pdst=target), timeout=5, retry=2, verbose=False)
                results = [{"ip": rcve.psrc, "mac": rcve.hwsrc} for sent, rcve in ans]
                logger.info(f"Scapy discovery found {len(results)} raw responses.")
                return results
            except Exception as e:
                logger.error(f"Scapy scan failed critical error: {e}")
                return []

        raw_devices = await asyncio.to_thread(network_discovery)
        
        # CRITICAL FIX: Deduplicate results BEFORE processing or saving.
        # This prevents 499+ devices being shown in the history.
        unique_devices_map = {}
        for d in raw_devices:
            key = (d["mac"] or d["ip"]).lower()
            if key not in unique_devices_map:
                unique_devices_map[key] = d
        
        unique_devices = list(unique_devices_map.values())
        logger.info(f"Filtered {len(raw_devices)} raw responses down to {len(unique_devices)} unique devices.")

        # 3. Parallelize device enrichment
        semaphore = asyncio.Semaphore(4)
        async def process_single_device(device):
            async with semaphore:
                ip, mac = device["ip"], device["mac"]
                hostname = await resolve_hostname(ip)
                # Keep discovery port scan minimal
                ports_list = await scan_ports(ip)
                return {"ip": ip, "mac": mac, "hostname": hostname, "ports_list": ports_list, "result_id": str(uuid.uuid4())}

        processed_results = []
        if unique_devices:
            processed_results = await asyncio.gather(*(process_single_device(d) for d in unique_devices))

        # 4. Save Results
        def save_and_update():
            conn = get_connection()
            try:
                save_now = datetime.now(timezone.utc)
                for res in processed_results:
                    ip, mac, hostname, ports_list, result_id = res["ip"], res["mac"], res["hostname"], res["ports_list"], res["result_id"]
                    
                    conn.execute(
                        "INSERT INTO scan_results (id, scan_id, ip, mac, hostname, open_ports, first_seen, last_seen) VALUES (?, ?, ?, ?, ?, ?, ?, ?)",
                        [result_id, scan_id, ip, mac, hostname, json.dumps(ports_list), save_now, save_now]
                    )
                conn.commit()
            finally:
                conn.close()
        
        if processed_results:
            await asyncio.to_thread(save_and_update)
            from app.services.devices import upsert_device_from_scan
            for res in processed_results:
                await upsert_device_from_scan(res["ip"], res["mac"], res["hostname"], res["ports_list"])

        # 5. Handle Offline state
        def finalize_scan():
            conn = get_connection()
            try:
                final_now = datetime.now(timezone.utc)
                offline_devices = conn.execute(
                    "SELECT id, ip, mac, display_name, vendor, icon FROM devices WHERE status = 'online' AND last_seen < ?",
                    [job_start]
                ).fetchall()
                
                for d_id, d_ip, d_mac, d_name, d_vendor, d_icon in offline_devices:
                    conn.execute("UPDATE devices SET status = 'offline' WHERE id = ?", [d_id])
                    conn.execute(
                        "INSERT INTO device_status_history (id, device_id, status, changed_at) VALUES (?, ?, ?, ?)",
                        [str(uuid.uuid4()), d_id, 'offline', final_now]
                    )

                conn.execute("UPDATE scans SET status = 'done', finished_at = ? WHERE id = ?", [final_now, scan_id])
                conn.commit()
                return offline_devices
            finally:
                conn.close()

        offline_list = await asyncio.to_thread(finalize_scan)
        
        # Publish MQTT
        from app.services.devices import publish_device_offline
        for d_id, d_ip, d_mac, d_name, d_vendor, d_icon in offline_list:
             await asyncio.to_thread(publish_device_offline, {
                "id": d_id, "ip": d_ip, "mac": d_mac, "hostname": d_name, "vendor": d_vendor,
                "icon": d_icon, "status": "offline", "timestamp": datetime.now(timezone.utc).isoformat()
            })

        logger.info(f"Scan job {scan_id} completed. Found {len(processed_results)} unique devices.")

    except Exception as e:
        logger.error(f"Scan job {scan_id} failed: {e}")
        def fail_scan():
            conn = get_connection()
            try:
                conn.execute("UPDATE scans SET status = 'error', finished_at = ?, error_message = ? WHERE id = ?", [datetime.now(timezone.utc), str(e), scan_id])
                conn.commit()
            finally:
                conn.close()
        await asyncio.to_thread(fail_scan)
        raise e
